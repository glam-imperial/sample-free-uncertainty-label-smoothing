---
  # General.
  method_string: "BD-fix0-SEResNet20-attention-4"
  model_path: ""
  results_summary_path: ""
  configuration_dict: ""
  gpu: 1

  train_batch_size: 8
  devel_batch_size: 8
  test_batch_size: 8

  # Evaluation.
  number_of_trials: 10
  val_every_n_epoch: 1
  are_test_labels_available: True

  # Training.
  initial_learning_rate: 0.00001
  number_of_epochs: 300
  patience: 15

  # Augmentation.
  # Add noise: DATA AUGMENTATION FOR ROBUST KEYWORD SPOTTING UNDER PLAYBACK INTERFERENCE
  # Amplitude augmentation.
  # SpeechAug
  input_gaussian_noise: 0.000001
  specaug: True
  mixup: False
  input_channels_aug: 1

  # Model.
  model_configuration:
    input_type_list:
      - logmel_spectrogram
    output_type_list:
      - whinny_single
    bottom_model: Identity  # [Identity, Wavegram, 1DCNN, 2DCNN]
    bottom_model_configuration:
      placeholder: ""
    core_model: VariationalResNet38_PANN  # [ResVGG16, CNN14_PANN, ResNet38_PANN, Hong, VGG16, RNN, Xception, MobileNet, EfficientNet, InceptionResNet]
    core_model_configuration:
      input_channels_aug: 1
      use_se: True
      use_tc: False
      use_ds: False
      max_pool_curiosity_initial_value: 0.0
      max_pool_curiosity_type: fixed
      uncertainty_handling: propagate
    global_pooling: VariationalAttention  # [Attention, LinearSoftmax, Average, Max, AvgMax_PANN, MaxPrediction, VGG16Top]
    global_pooling_configuration:
      number_of_heads: 4
      use_temporal_std: False
      pool_heads: no_pool  # [no_pool, gating, attention]
      auto_pooling: no_auto  # [no_auto, Auto, MultiResolution, GumbelSoftmax]
      use_auto_array: False
      uncertainty_handling: propagate
      number_of_features: 4096
      sequence_length: 9
    bayesian:
      kl_loss_regulariser: 0.000000000001  #       kl_loss_regulariser: 0.0000000001
      use_logit_vars: True
